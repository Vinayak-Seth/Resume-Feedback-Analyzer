{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q pytesseract pdf2image sentence-transformers transformers faiss-cpu poppler-utils PyPDF2\n",
        "import re\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download required NLTK data\n",
        "import nltk\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "class ImprovedResumeAnalyzer:\n",
        "    def __init__(self):\n",
        "        print(\"üöÄ Initializing Improved Resume Analyzer...\")\n",
        "\n",
        "        # Load embedding model\n",
        "        self.embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "        # Load text generation model (optional, with fallback)\n",
        "        self.generator = None\n",
        "        try:\n",
        "            print(\"üì• Loading text generation model...\")\n",
        "            self.generator = pipeline(\n",
        "                \"text2text-generation\",\n",
        "                model=\"google/flan-t5-base\",  # Using base for reliability\n",
        "                max_length=512,\n",
        "                device=0 if torch.cuda.is_available() else -1\n",
        "            )\n",
        "            print(\"‚úÖ Text generation model loaded!\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Text generation model not available: {e}\")\n",
        "            print(\"üìù Will use rule-based feedback generation\")\n",
        "\n",
        "        # Define comprehensive skill categories\n",
        "        self.skill_categories = {\n",
        "            'programming': [\n",
        "                'python', 'java', 'javascript', 'typescript', 'c++', 'c#', 'php',\n",
        "                'ruby', 'go', 'rust', 'swift', 'kotlin', 'scala', 'r','c','swift'\n",
        "            ],\n",
        "            'web_technologies': [\n",
        "                'react', 'angular', 'vue', 'node.js', 'express', 'django',\n",
        "                'flask', 'spring', 'laravel', 'html', 'css', 'bootstrap'\n",
        "            ],\n",
        "            'databases': [\n",
        "                'sql', 'mysql', 'postgresql', 'mongodb', 'redis', 'elasticsearch',\n",
        "                'oracle', 'sqlite', 'cassandra', 'dynamodb','nosql'\n",
        "            ],\n",
        "            'cloud_devops': [\n",
        "                'aws', 'azure', 'gcp', 'docker', 'kubernetes', 'jenkins',\n",
        "                'terraform', 'ansible', 'git', 'ci/cd', 'devops'\n",
        "            ],\n",
        "            'data_science': [\n",
        "                'machine learning', 'deep learning', 'data science', 'analytics',\n",
        "                'statistics', 'pandas', 'numpy', 'scikit-learn', 'tensorflow',\n",
        "                'pytorch', 'tableau', 'power bi','excel','seaborn','matplotlib'\n",
        "            ],\n",
        "            'soft_skills': [\n",
        "                'leadership', 'communication', 'project management', 'agile',\n",
        "                'scrum', 'teamwork', 'problem solving', 'analytical thinking'\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        print(\"‚úÖ Analyzer initialized successfully!\")\n",
        "\n",
        "    def extract_text_from_pdf(self, pdf_path):\n",
        "        \"\"\"Extract text from PDF with multiple fallback methods\"\"\"\n",
        "        methods_tried = []\n",
        "\n",
        "        # Method 1: PyPDF2\n",
        "        try:\n",
        "            from PyPDF2 import PdfReader\n",
        "            reader = PdfReader(pdf_path)\n",
        "            text = \" \".join([page.extract_text() or \"\" for page in reader.pages])\n",
        "            if len(text.strip()) > 100:  # Reasonable amount of text\n",
        "                return text, \"PyPDF2\"\n",
        "            methods_tried.append(\"PyPDF2 (insufficient text)\")\n",
        "        except Exception as e:\n",
        "            methods_tried.append(f\"PyPDF2 failed: {str(e)[:50]}\")\n",
        "\n",
        "        # Method 2: pdfplumber (if available)\n",
        "        try:\n",
        "            import pdfplumber\n",
        "            text = \"\"\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                for page in pdf.pages:\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text:\n",
        "                        text += page_text + \"\\n\"\n",
        "            if len(text.strip()) > 100:\n",
        "                return text, \"pdfplumber\"\n",
        "            methods_tried.append(\"pdfplumber (insufficient text)\")\n",
        "        except ImportError:\n",
        "            methods_tried.append(\"pdfplumber not available\")\n",
        "        except Exception as e:\n",
        "            methods_tried.append(f\"pdfplumber failed: {str(e)[:50]}\")\n",
        "\n",
        "        # Method 3: OCR with pytesseract\n",
        "        try:\n",
        "            from pdf2image import convert_from_path\n",
        "            import pytesseract\n",
        "\n",
        "            images = convert_from_path(pdf_path)\n",
        "            text = \"\"\n",
        "            for i, img in enumerate(images):\n",
        "                page_text = pytesseract.image_to_string(img)\n",
        "                text += f\"\\n--- Page {i+1} ---\\n{page_text}\"\n",
        "\n",
        "            if len(text.strip()) > 50:\n",
        "                return text, \"OCR\"\n",
        "            methods_tried.append(\"OCR (insufficient text)\")\n",
        "        except Exception as e:\n",
        "            methods_tried.append(f\"OCR failed: {str(e)[:50]}\")\n",
        "\n",
        "        print(f\"‚ùå All extraction methods failed: {methods_tried}\")\n",
        "        return \"\", \"failed\"\n",
        "\n",
        "    def clean_and_normalize_text(self, text):\n",
        "        \"\"\"Advanced text cleaning and normalization\"\"\"\n",
        "        # Remove extra whitespace and normalize\n",
        "        text = re.sub(r'\\s+', ' ', text.strip())\n",
        "\n",
        "        # Remove special characters but keep important punctuation\n",
        "        text = re.sub(r'[^\\w\\s\\.\\,\\;\\:\\-\\+\\#$$$$]', ' ', text)\n",
        "\n",
        "        # Normalize common variations\n",
        "        text = re.sub(r'\\bC\\+\\+\\b', 'cpp', text, flags=re.IGNORECASE)\n",
        "        text = re.sub(r'\\bC#\\b', 'csharp', text, flags=re.IGNORECASE)\n",
        "        text = re.sub(r'\\bNode\\.js\\b', 'nodejs', text, flags=re.IGNORECASE)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def calculate_cosine_similarity(self, text1, text2):\n",
        "        \"\"\"Calculate cosine similarity between two texts\"\"\"\n",
        "        # Generate embeddings\n",
        "        embeddings = self.embed_model.encode([text1, text2])\n",
        "\n",
        "        # Calculate cosine similarity\n",
        "        embedding1, embedding2 = embeddings[0], embeddings[1]\n",
        "\n",
        "        # Cosine similarity formula\n",
        "        dot_product = np.dot(embedding1, embedding2)\n",
        "        norm1 = np.linalg.norm(embedding1)\n",
        "        norm2 = np.linalg.norm(embedding2)\n",
        "\n",
        "        if norm1 == 0 or norm2 == 0:\n",
        "            return 0.0\n",
        "\n",
        "        cosine_sim = dot_product / (norm1 * norm2)\n",
        "\n",
        "        # Convert to percentage (0-100)\n",
        "        similarity_percentage = max(0, min(100, cosine_sim * 100))\n",
        "\n",
        "        return similarity_percentage, cosine_sim\n",
        "\n",
        "    def extract_skills_advanced(self, text):\n",
        "        \"\"\"Advanced skill extraction with categorization\"\"\"\n",
        "        text_lower = text.lower()\n",
        "        found_skills = {}\n",
        "\n",
        "        for category, skills in self.skill_categories.items():\n",
        "            found_skills[category] = []\n",
        "            for skill in skills:\n",
        "                # Use word boundaries for better matching\n",
        "                pattern = r'\\b' + re.escape(skill.lower()) + r'\\b'\n",
        "                if re.search(pattern, text_lower):\n",
        "                    found_skills[category].append(skill)\n",
        "\n",
        "        return found_skills\n",
        "\n",
        "    def generate_comprehensive_feedback(self, resume_text, jd_text, similarity_score, resume_skills, jd_skills):\n",
        "        \"\"\"Generate comprehensive feedback\"\"\"\n",
        "\n",
        "        # Find matches and gaps\n",
        "        all_resume_skills = set()\n",
        "        all_jd_skills = set()\n",
        "\n",
        "        for category in resume_skills:\n",
        "            all_resume_skills.update(resume_skills[category])\n",
        "        for category in jd_skills:\n",
        "            all_jd_skills.update(jd_skills[category])\n",
        "\n",
        "        matching_skills = all_resume_skills.intersection(all_jd_skills)\n",
        "        missing_skills = all_jd_skills - all_resume_skills\n",
        "\n",
        "        # Generate feedback based on similarity score\n",
        "        if similarity_score >= 80:\n",
        "            overall_assessment = \"EXCELLENT MATCH! üéâ\"\n",
        "            priority = \"Focus on fine-tuning and formatting\"\n",
        "        elif similarity_score >= 65:\n",
        "            overall_assessment = \"GOOD MATCH! üëç\"\n",
        "            priority = \"Address missing skills and add more specific examples\"\n",
        "        elif similarity_score >= 50:\n",
        "            overall_assessment = \"MODERATE MATCH üìä\"\n",
        "            priority = \"Significant improvements needed in skill alignment\"\n",
        "        else:\n",
        "            overall_assessment = \"LOW MATCH ‚ö†Ô∏è\"\n",
        "            priority = \"Major restructuring recommended\"\n",
        "\n",
        "        feedback = f\"\"\"\n",
        "üéØ RESUME ANALYSIS RESULTS\n",
        "{'='*60}\n",
        "\n",
        "üìä SIMILARITY SCORE: {similarity_score:.1f}%\n",
        "üéØ OVERALL ASSESSMENT: {overall_assessment}\n",
        "üîç PRIORITY: {priority}\n",
        "\n",
        "‚úÖ MATCHING SKILLS ({len(matching_skills)} found):\n",
        "{self._format_skills_list(matching_skills)}\n",
        "\n",
        "‚ùå MISSING CRITICAL SKILLS ({len(missing_skills)} identified):\n",
        "{self._format_skills_list(missing_skills)}\n",
        "\n",
        "üìà SKILL BREAKDOWN BY CATEGORY:\n",
        "{self._format_skill_breakdown(resume_skills, jd_skills)}\n",
        "\n",
        "üõ†Ô∏è SPECIFIC IMPROVEMENT RECOMMENDATIONS:\n",
        "\n",
        "1. CONTENT IMPROVEMENTS:\n",
        "   ‚Ä¢ Add quantifiable achievements (e.g., \"Increased efficiency by 25%\")\n",
        "   ‚Ä¢ Include specific project examples that demonstrate required skills\n",
        "   ‚Ä¢ Highlight leadership and collaboration experiences\n",
        "\n",
        "2. KEYWORD OPTIMIZATION:\n",
        "   ‚Ä¢ Naturally incorporate missing keywords: {', '.join(list(missing_skills)[:5])}\n",
        "   ‚Ä¢ Use industry-standard terminology from the job description\n",
        "   ‚Ä¢ Add relevant certifications or training\n",
        "\n",
        "3. STRUCTURE & FORMATTING:\n",
        "   ‚Ä¢ Create a professional summary that mirrors the job requirements\n",
        "   ‚Ä¢ Use bullet points with strong action verbs\n",
        "   ‚Ä¢ Ensure consistent formatting and clear section headers\n",
        "\n",
        "4. SKILL DEMONSTRATION:\n",
        "   ‚Ä¢ Provide context for each technical skill mentioned\n",
        "   ‚Ä¢ Show progression and growth in your career\n",
        "   ‚Ä¢ Include relevant side projects or contributions\n",
        "\n",
        "{'='*60}\n",
        "\"\"\"\n",
        "        return feedback\n",
        "\n",
        "    def _format_skills_list(self, skills):\n",
        "        \"\"\"Format skills list for display\"\"\"\n",
        "        if not skills:\n",
        "            return \"   ‚Ä¢ None identified\"\n",
        "\n",
        "        skills_list = sorted(list(skills))\n",
        "        if len(skills_list) <= 10:\n",
        "            return '\\n'.join([f\"   ‚Ä¢ {skill.title()}\" for skill in skills_list])\n",
        "        else:\n",
        "            displayed = skills_list[:8]\n",
        "            remaining = len(skills_list) - 8\n",
        "            result = '\\n'.join([f\"   ‚Ä¢ {skill.title()}\" for skill in displayed])\n",
        "            result += f\"\\n   ‚Ä¢ ... and {remaining} more\"\n",
        "            return result\n",
        "\n",
        "    def _format_skill_breakdown(self, resume_skills, jd_skills):\n",
        "        \"\"\"Format skill breakdown by category\"\"\"\n",
        "        breakdown = \"\"\n",
        "        for category in self.skill_categories.keys():\n",
        "            resume_count = len(resume_skills.get(category, []))\n",
        "            jd_count = len(jd_skills.get(category, []))\n",
        "\n",
        "            if jd_count > 0:  # Only show categories that are relevant to the job\n",
        "                match_rate = (resume_count / jd_count * 100) if jd_count > 0 else 0\n",
        "                status = \"‚úÖ\" if match_rate >= 70 else \"‚ö†Ô∏è\" if match_rate >= 40 else \"‚ùå\"\n",
        "\n",
        "                breakdown += f\"   {status} {category.replace('_', ' ').title()}: \"\n",
        "                breakdown += f\"{resume_count}/{jd_count} skills ({match_rate:.0f}%)\\n\"\n",
        "\n",
        "        return breakdown.strip() if breakdown else \"   ‚Ä¢ No specific skill categories identified\"\n",
        "\n",
        "    def analyze_resume(self):\n",
        "        \"\"\"Main analysis function\"\"\"\n",
        "        print(\"üéØ IMPROVED RESUME FEEDBACK ASSISTANT\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # File uploads\n",
        "        print(\"\\nüì§ Upload your Resume (PDF format):\")\n",
        "        uploaded_resume = files.upload()\n",
        "        if not uploaded_resume:\n",
        "            print(\"‚ùå No resume uploaded!\")\n",
        "            return None\n",
        "\n",
        "        resume_path = list(uploaded_resume.keys())[0]\n",
        "\n",
        "        print(\"\\nüì§ Upload Job Description (TXT format):\")\n",
        "        uploaded_jd = files.upload()\n",
        "        if not uploaded_jd:\n",
        "            print(\"‚ùå No job description uploaded!\")\n",
        "            return None\n",
        "\n",
        "        jd_path = list(uploaded_jd.keys())[0]\n",
        "\n",
        "        # Extract and process texts\n",
        "        print(\"\\nüîç Extracting text from resume...\")\n",
        "        resume_text, resume_method = self.extract_text_from_pdf(resume_path)\n",
        "\n",
        "        if not resume_text:\n",
        "            print(\"‚ùå Failed to extract text from resume!\")\n",
        "            return None\n",
        "\n",
        "        resume_text = self.clean_and_normalize_text(resume_text)\n",
        "        print(f\"‚úÖ Resume text extracted using {resume_method} ({len(resume_text)} characters)\")\n",
        "\n",
        "        print(\"\\nüìñ Reading job description...\")\n",
        "        try:\n",
        "            with open(jd_path, 'r', encoding='utf-8') as f:\n",
        "                jd_text = self.clean_and_normalize_text(f.read())\n",
        "            print(f\"‚úÖ Job description loaded ({len(jd_text)} characters)\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to read job description: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "        # Calculate similarity using cosine similarity (most reliable method)\n",
        "        print(\"\\nüßÆ Calculating similarity score...\")\n",
        "        similarity_score, raw_cosine = self.calculate_cosine_similarity(resume_text, jd_text)\n",
        "        print(f\"üìä Cosine Similarity: {raw_cosine:.4f}\")\n",
        "        print(f\"üìä Similarity Score: {similarity_score:.1f}%\")\n",
        "\n",
        "        # Extract skills\n",
        "        print(\"\\nüîç Analyzing skills...\")\n",
        "        resume_skills = self.extract_skills_advanced(resume_text)\n",
        "        jd_skills = self.extract_skills_advanced(jd_text)\n",
        "\n",
        "        # Generate comprehensive feedback\n",
        "        print(\"\\nüìù Generating comprehensive feedback...\")\n",
        "        feedback = self.generate_comprehensive_feedback(\n",
        "            resume_text, jd_text, similarity_score, resume_skills, jd_skills\n",
        "        )\n",
        "\n",
        "        # Display results\n",
        "        print(feedback)\n",
        "\n",
        "        return {\n",
        "            'similarity_score': similarity_score,\n",
        "            'raw_cosine_similarity': raw_cosine,\n",
        "            'feedback': feedback,\n",
        "            'resume_skills': resume_skills,\n",
        "            'jd_skills': jd_skills,\n",
        "            'extraction_method': resume_method\n",
        "        }\n",
        "\n",
        "# Initialize and run the improved analyzer\n",
        "if __name__ == \"__main__\":\n",
        "    analyzer = ImprovedResumeAnalyzer()\n",
        "    results = analyzer.analyze_resume()"
      ],
      "metadata": {
        "id": "Fq3soV8dP4zC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
